import type { InferSchema, Schema } from '../../../utils'

export const languageModelParametersSchema = {
  type: 'object',
  additionalProperties: false,
  properties: {
    temperature: {
      'type': 'number',
      'title': 'Temperature',
      'description': 'The sampling temperature for the completion.',
      'default': 1,
      'x-control': 'slider',
      'x-slider-min': 0.1,
      'x-slider-max': 2,
      'x-slider-step': 0.1,
    },
    frequencyPenalty: {
      'type': 'number',
      'title': 'Frequency Penalty',
      'description': 'Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model\'s likelihood to repeat the same line verbatim.',
      'x-control': 'slider',
      'x-slider-min': -2,
      'x-slider-max': 2,
      'x-slider-step': 0.1,
    },
    logitBias: {
      'type': 'number',
      'title': 'Logit Bias',
      'description': 'Modify the likelihood of specified tokens appearing in the completion. Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.',
      'default': 0,
      'x-control': 'slider',
      'x-slider-min': -100,
      'x-slider-max': 100,
      'x-slider-step': 1,
    },
    maxCompletionTokens: {
      'type': 'number',
      'title': 'Max Tokens',
      'description': 'The maximum number of tokens to generate the completion.',
      'default': 1024,
      'x-control': 'slider',
      'x-slider-min': 0,
      'x-slider-max': 2 ** 16,
      'x-slider-step': 64,
    },
    maxToolCalls: {
      'type': 'number',
      'title': 'Max Tool Calls',
      'description': 'The maximum number of tool calls to handle in the completion process.',
      'default': 10,
      'x-control': 'slider',
      'x-slider-min': 0,
      'x-slider-max': 100,
    },
    allowParallelToolCalls: {
      type: 'boolean',
      title: 'Allow Parallel Tool Calls',
      description: 'Whether to allow parallel tool calls.',
      default: false,
    },
    seed: {
      'type': 'number',
      'title': 'Seed',
      'description': 'The seed used to generate the completion.',
      'x-control': 'slider',
      'x-optional': true,
    },
    topK: {
      'type': 'number',
      'title': 'Top K',
      'description': 'The number of highest probability vocabulary tokens to keep for top-k sampling.',
      'default': 0,
      'x-control': 'slider',
      'x-slider-min': 0,
      'x-slider-max': 100,
    },
    topP: {
      'type': 'number',
      'title': 'Top P',
      'description': 'The cumulative probability of parameter settings for nucleus sampling.',
      'default': 1,
      'x-control': 'slider',
      'x-slider-min': 0,
      'x-slider-max': 1,
      'x-slider-step': 0.01,
    },
    stopSequences: {
      'type': 'array',
      'title': 'Stop Sequence',
      'description': 'An array of strings that will stop the completion when generated.',
      'items': { type: 'string' },
      'x-control': 'tags',
    },
    stream: {
      type: 'boolean',
      title: 'Stream',
      description: 'Whether to stream the completion response.',
      default: true,
    },
  },
} as const satisfies Schema

export type LanguageModelParameters = InferSchema<typeof languageModelParametersSchema>
